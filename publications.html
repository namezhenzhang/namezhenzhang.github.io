<!DOCTYPE html>
<!-- 
  Generated by Config-Driven Academic Website Template
  Author: Sixun Dong (ironieser)
  Repository: https://github.com/Ironieser/ironieser.github.io
  License: MIT
-->
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Publications - Sixun Dong (Ironieser)</title>
    
    <!-- SEO Meta Tags -->
    <meta name="description" content="Publications by Sixun Dong - Multimodal Learning, VLM, LLM Agent at Arizona State University. Research in multimodal AI systems, computer vision, natural language processing, machine learning">
    <meta name="keywords" content="computer vision, multimodal AI, machine learning, deep learning, artificial intelligence, academic research, Sixun Dong, Ironieser, publications, papers, research papers">
    <meta name="author" content="Sixun Dong">
    
    <!-- Open Graph Meta Tags -->
    <meta property="og:title" content="Publications - Sixun Dong">
    <meta property="og:description" content="Publications by Sixun Dong - Multimodal Learning, VLM, LLM Agent at Arizona State University">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://cv.ironieser.cc/publications.html">
    <meta property="og:image" content="https://cv.ironieser.cc/images/logo.jpg">
    
    <!-- Twitter Card Meta Tags -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Publications - Sixun Dong">
    <meta name="twitter:description" content="Publications by Sixun Dong - Multimodal Learning, VLM, LLM Agent at Arizona State University">
    <meta name="twitter:image" content="https://cv.ironieser.cc/images/logo.jpg">
    
    <!-- JSON-LD Structured Data -->
    <script type="application/ld+json">
[
  {
    "@context": "https://schema.org",
    "@type": "Person",
    "name": "Sixun Dong",
    "alternateName": "Ironieser",
    "email": "ironieser@gmail.com",
    "jobTitle": "PhD Student in Computer Science",
    "affiliation": {
      "@type": "Organization",
      "name": "Arizona State University",
      "url": "https://www.asu.edu",
      "address": {
        "@type": "PostalAddress",
        "addressCountry": "USA",
        "addressLocality": "Tempe",
        "addressRegion": "AZ"
      }
    },
    "url": "https://cv.ironieser.cc",
    "sameAs": [
      "https://scholar.google.com/citations?user=j71Y2-4AAAAJ",
      "https://github.com/Ironieser",
      "https://twitter.com/ironieser",
      "https://cv.ironieser.cc",
      "https://ironieser.github.io"
    ],
    "knowsAbout": [
      "multimodal AI systems",
      "computer vision",
      "natural language processing",
      "machine learning"
    ],
    "image": "https://cv.ironieser.cc/images/logo.jpg"
  },
  {
    "@context": "https://schema.org",
    "@type": "WebSite",
    "name": "Sixun Dong (Ironieser) - Academic Homepage",
    "description": "PhD Student in Computer Science at Arizona State University, focusing on multimodal AI systems, computer vision, and machine learning",
    "url": "https://cv.ironieser.cc",
    "author": {
      "@type": "Person",
      "name": "Sixun Dong"
    },
    "publisher": {
      "@type": "Organization",
      "name": "Arizona State University",
      "url": "https://www.asu.edu"
    }
  },
  {
    "@type": "ScholarlyArticle",
    "name": "TransRAC: Encoding Multi-scale Temporal Correlation with Transformers for Repetitive Action Counting",
    "author": [
      {
        "@type": "Person",
        "name": "Huazhang Hu*"
      },
      {
        "@type": "Person",
        "name": "Sixun Dong*"
      },
      {
        "@type": "Person",
        "name": "Yiqun Zhao"
      },
      {
        "@type": "Person",
        "name": "Dongze Lian"
      },
      {
        "@type": "Person",
        "name": "Zhengxin Li"
      },
      {
        "@type": "Person",
        "name": "Shenghua Gao"
      }
    ],
    "datePublished": "2022-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CVPR'22"
    },
    "url": "https://arxiv.org/abs/2204.01018"
  },
  {
    "@type": "ScholarlyArticle",
    "name": "Weakly Supervised Video Representation Learning with Unaligned Text for Sequential Videos",
    "author": [
      {
        "@type": "Person",
        "name": "Sixun Dong*"
      },
      {
        "@type": "Person",
        "name": "Huazhang Hu*"
      },
      {
        "@type": "Person",
        "name": "Dongze Lian"
      },
      {
        "@type": "Person",
        "name": "Weixin Luo"
      },
      {
        "@type": "Person",
        "name": "Yicheng Qian"
      },
      {
        "@type": "Person",
        "name": "Shenghua Gao"
      }
    ],
    "datePublished": "2023-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CVPR'23"
    },
    "url": "https://arxiv.org/abs/2303.12370"
  },
  {
    "@type": "ScholarlyArticle",
    "name": "MLLM-Tool: A Multimodal Large Language Model For Tool Agent Learning",
    "author": [
      {
        "@type": "Person",
        "name": "Chenyu Wang"
      },
      {
        "@type": "Person",
        "name": "Weixin Luo"
      },
      {
        "@type": "Person",
        "name": "Sixun Dong"
      },
      {
        "@type": "Person",
        "name": "Xiaohua Xuan"
      },
      {
        "@type": "Person",
        "name": "Zhengxin Li"
      },
      {
        "@type": "Person",
        "name": "Lin Ma"
      },
      {
        "@type": "Person",
        "name": "Shenghua Gao"
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "WACV'25"
    },
    "url": "https://arxiv.org/abs/2401.10727"
  },
  {
    "@type": "ScholarlyArticle",
    "name": "RoomDesigner: Encoding Anchor-latents for Style-consistent and Shape-compatible Indoor Scene Generation",
    "author": [
      {
        "@type": "Person",
        "name": "Yiqun Zhao"
      },
      {
        "@type": "Person",
        "name": "Zibo Zhao"
      },
      {
        "@type": "Person",
        "name": "Jing Li"
      },
      {
        "@type": "Person",
        "name": "Sixun Dong"
      },
      {
        "@type": "Person",
        "name": "Shenghua Gao"
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "3DV'24"
    },
    "url": "https://arxiv.org/abs/2310.10027"
  },
  {
    "@type": "ScholarlyArticle",
    "name": "Sculpting Features from Noise: Reward-Guided Hierarchical Diffusion for Task-Optimal Feature Transformation",
    "author": [
      {
        "@type": "Person",
        "name": "Nanxu Gong*"
      },
      {
        "@type": "Person",
        "name": "Zijun Li*"
      },
      {
        "@type": "Person",
        "name": "Sixun Dong"
      },
      {
        "@type": "Person",
        "name": "Haoyue Bai"
      },
      {
        "@type": "Person",
        "name": "Wangyang Ying"
      },
      {
        "@type": "Person",
        "name": "Xinyuan Wang"
      },
      {
        "@type": "Person",
        "name": "Yanjie Fu"
      }
    ],
    "datePublished": "2025-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "NeurIPS'25"
    },
    "url": "https://arxiv.org/abs/2505.15152"
  },
  {
    "@type": "ScholarlyArticle",
    "name": "Unsupervised feature transformation via in-context generation, generator-critic llm agents, and duet-play teaming",
    "author": [
      {
        "@type": "Person",
        "name": "Nanxu Gong"
      },
      {
        "@type": "Person",
        "name": "Xinyuan Wang"
      },
      {
        "@type": "Person",
        "name": "Wangyang Ying"
      },
      {
        "@type": "Person",
        "name": "Haoyue Bai"
      },
      {
        "@type": "Person",
        "name": "Sixun Dong"
      },
      {
        "@type": "Person",
        "name": "Haifeng Chen"
      },
      {
        "@type": "Person",
        "name": "Yanjie Fu"
      }
    ],
    "datePublished": "2025-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "IJCAI'25"
    },
    "url": "https://arxiv.org/abs/2504.21304"
  }
]
</script>
    
    <!-- Favicon -->
    <link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
    <link rel="apple-touch-icon" sizes="180x180" href="apple-touch-icon.png">
    <link rel="shortcut icon" href="favicon.ico">
    
    <link rel="stylesheet" href="styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
</head>
<body>
    <!-- Navigation -->
    <header class="header">
        <nav class="nav">
            <div class="nav-container">
                <a href="index.html" class="nav-link " >Bio</a>
                <a href="publications.html" class="nav-link active" >Publications</a>
                <a href="blog.html" class="nav-link " >Blog</a>
                <a href="#" class="nav-link " target="_blank">CV(PDF)</a>
            </div>
        </nav>
    </header>

    <!-- Main Content -->
    <main class="main">
        <!-- Page Header -->
        <section class="page-header">
            <div class="container">
                <div class="page-header-content">
                    <h1 class="page-title-left">Publications</h1>
                    <div class="research-intro">
                        <p>Currently, my research focuses on <strong>multimodal AI systems</strong> that bridge computer vision, natural language processing, and machine learning. I work on developing intelligent agents that can understand and generate content across multiple modalities, with applications in video analysis, time series forecasting, and feature transformation.</p>
                    </div>
                    
                    <!-- Summary Stats Bar -->
                    <div class="publication-stats-bar">
                        <span class="stat-item">10+ publications</span> <span class="stat-divider">‚Ä¢</span> <span class="stat-item">5 top-tier venues (CVPR, NeurIPS, WACV, IJCAI, 3DV)</span> <span class="stat-divider">‚Ä¢</span> <span class="stat-item">1 oral presentation</span>
                    </div>
                </div>
            </div>
        </section>

        <!-- Publications -->
        <section class="section">
            <div class="container">
                
            <div class="year-group">
                <h3 class="year-title">2025</h3>
                <div class="publications-list">
                    
                <div class="publication-item">
                    <img src="images/blog/mmtok/combined_plots.png" alt="MMTok: Multimodal Coverage Maximization for Efficient Inference of VLMs" class="publication-image teaser" onerror="this.src='images/default-paper.png'">
                    <div class="publication-content">
                        <p class="publication-title"><span class="publication-venue-preprint">arXiv'2508</span> MMTok: Multimodal Coverage Maximization for Efficient Inference of VLMs</p>
                        <p class="publication-authors"><span class="author-highlight">Sixun Dong</span>, Juhua Hu, Mian Zhang, Ming Yin, Yanjie Fu, Qi Qian</p>
                        <p class="publication-links"><i class="ai ai-arxiv"></i> <a href="https://arxiv.org/abs/2508.18264" target="_blank">Paper</a> / <i class="fab fa-github"></i> <a href="https://github.com/Ironieser/MMTok" target="_blank">Code</a> / <i class="fas fa-home"></i> <a href="https://project.ironieser.cc/mmtok" target="_blank">Homepage</a> / <i class="fas fa-book-open"></i> <a href="https://zhuanlan.zhihu.com/p/1944299907109348831" target="_blank">Áü•‰πé</a></p>
                    </div>
                </div>
                <div class="publication-item">
                    <img src="teaser/MCP101.jpg" alt="LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries" class="publication-image teaser" onerror="this.src='images/default-paper.png'">
                    <div class="publication-content">
                        <p class="publication-title"><span class="publication-venue-preprint">arXiv'2508</span> LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries</p>
                        <p class="publication-authors">Ming Yin, Dinghan Shen, Silei Xu, Jianbing Han, <span class="author-highlight">Sixun Dong</span>, Mian Zhang, Yebowen Hu, Shujian Liu, Simin Ma, Song Wang, Sathish Reddy Indurthi, Xun Wang, Yiran Chen, Kaiqiang Song</p>
                        <p class="publication-links"><i class="ai ai-arxiv"></i> <a href="https://arxiv.org/abs/2508.15760" target="_blank">Paper</a> / <i class="fab fa-github"></i> <span class="coming-soon">Code</span> / <i class="fas fa-database"></i> <span class="coming-soon">Benchmark</span> / <i class="fas fa-book-open"></i> <a href="https://zhuanlan.zhihu.com/p/1949009535743264421" target="_blank">Áü•‰πé</a></p>
                    </div>
                </div>
                <div class="publication-item">
                    <img src="teaser/logitif.jpg" alt="Complex Logical Instruction Generation" class="publication-image teaser" onerror="this.src='images/default-paper.png'">
                    <div class="publication-content">
                        <p class="publication-title"><span class="publication-venue-preprint">arXiv'2508</span> Complex Logical Instruction Generation</p>
                        <p class="publication-authors">Mian Zhang, Shujian Liu, <span class="author-highlight">Sixun Dong</span>, Ming Yin, Yebowen Hu, Xun Wang, Steven Ma, Song Wang, Sathish Reddy Indurthi, Haoyun Deng, Zhiyu Zoey Chen, Kaiqiang Song</p>
                        <p class="publication-links"><i class="ai ai-arxiv"></i> <a href="https://arxiv.org/abs/2508.09125" target="_blank">Paper</a> / <i class="fab fa-github"></i> <a href="https://github.com/mianzhang/LogicIF" target="_blank">Code</a> / <i class="fas fa-database"></i> <a href="https://github.com/mianzhang/LogicIF" target="_blank">Benchmark</a> / <i class="fas fa-book-open"></i> <a href="https://zhuanlan.zhihu.com/p/1941376510113059206" target="_blank">Áü•‰πé</a></p>
                    </div>
                </div>
                <div class="publication-item">
                    <img src="images/blog/timesclip/fig3.png" alt="Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives" class="publication-image teaser" onerror="this.src='images/default-paper.png'">
                    <div class="publication-content">
                        <p class="publication-title"><span class="publication-venue-under-review">arXiv'2506</span> Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives</p>
                        <p class="publication-authors"><span class="author-highlight">Sixun Dong</span>, Wei Fan, Teresa Wu, Yanjie Fu</p>
                        <p class="publication-links"><i class="ai ai-arxiv"></i> <a href="https://arxiv.org/abs/2506.24124" target="_blank">Paper</a> / <i class="fab fa-github"></i> <a href="https://github.com/Ironieser/TimesCLIP" target="_blank">Code</a> / <i class="fas fa-home"></i> <a href="https://cv.ironieser.cc/projects/timesclip.html" target="_blank">Homepage</a> / <i class="fas fa-blog"></i> <a href="https://cv.ironieser.cc/blog.html#timesclip-time-series-forecasting" target="_blank">Blog</a> / <i class="fas fa-book-open"></i> <a href="https://zhuanlan.zhihu.com/p/1936813469446940130" target="_blank">Áü•‰πé</a></p>
                    </div>
                </div>
                <div class="publication-item">
                    <img src="teaser/underreview.jpg" alt="TimesFrame: Multi-Variable Time Series is a Video of Numerical Data" class="publication-image teaser" onerror="this.src='images/default-paper.png'">
                    <div class="publication-content">
                        <p class="publication-title"><span class="publication-venue-under-review">Under Review</span> TimesFrame: Multi-Variable Time Series is a Video of Numerical Data</p>
                        <p class="publication-authors"><span class="author-highlight">Sixun Dong</span>, Nanxu Gong, Haoyue Bai, Xinyuan Wang, Wangyang Ying, Wei Fan, Yanjie Fu</p>
                        <p class="publication-links"><i class="ai ai-arxiv"></i> <span class="coming-soon">Paper (Coming Soon)</span></p>
                    </div>
                </div>
                <div class="publication-item">
                    <img src="teaser/agentic.jpg" alt="Agentic Feature Augmentation: Unifying Selection and Generation with Teaming, Planning, and Memories" class="publication-image teaser" onerror="this.src='images/default-paper.png'">
                    <div class="publication-content">
                        <p class="publication-title"><span class="publication-venue-under-review">arXiv'2505</span> Agentic Feature Augmentation: Unifying Selection and Generation with Teaming, Planning, and Memories</p>
                        <p class="publication-authors">Nanxu Gong*, <span class="author-highlight">Sixun Dong*</span>, Haoyue Bai, Xinyuan Wang, Wangyang Ying, Yanjie Fu</p>
                        <p class="publication-links"><i class="ai ai-arxiv"></i> <a href="https://arxiv.org/abs/2505.15076" target="_blank">Paper</a></p>
                    </div>
                </div>
                <div class="publication-item">
                    <img src="teaser/sculp.jpg" alt="Sculpting Features from Noise: Reward-Guided Hierarchical Diffusion for Task-Optimal Feature Transformation" class="publication-image teaser" onerror="this.src='images/default-paper.png'">
                    <div class="publication-content">
                        <p class="publication-title"><span class="publication-venue">NeurIPS'25</span> Sculpting Features from Noise: Reward-Guided Hierarchical Diffusion for Task-Optimal Feature Transformation</p>
                        <p class="publication-authors">Nanxu Gong*, Zijun Li*, <span class="author-highlight">Sixun Dong</span>, Haoyue Bai, Wangyang Ying, Xinyuan Wang, Yanjie Fu</p>
                        <p class="publication-links"><i class="ai ai-arxiv"></i> <a href="https://arxiv.org/abs/2505.15152" target="_blank">Paper</a> / <i class="fab fa-github"></i> <a href="https://github.com/NanxuGong/DIFFT" target="_blank">Code</a> / <i class="fas fa-book-open"></i> <a href="https://zhuanlan.zhihu.com/p/1933301751826429982" target="_blank">Áü•‰πé</a></p>
                    </div>
                </div>
                <div class="publication-item">
                    <img src="teaser/underreview.jpg" alt="MECT: From Multimodal Knowledge Acquisition To Contrastive Embedding Construction For Generative Feature Transformation" class="publication-image teaser" onerror="this.src='images/default-paper.png'">
                    <div class="publication-content">
                        <p class="publication-title"><span class="publication-venue-under-review">Under Review</span> MECT: From Multimodal Knowledge Acquisition To Contrastive Embedding Construction For Generative Feature Transformation</p>
                        <p class="publication-authors">Nanxu Gong, <span class="author-highlight">Sixun Dong</span>, Haoyue Bai, Wangyang Ying, Yanjie Fu</p>
                        <p class="publication-links"><i class="ai ai-arxiv"></i> <span class="coming-soon">Paper (Coming Soon)</span></p>
                    </div>
                </div>
                <div class="publication-item">
                    <img src="teaser/agentFt.jpg" alt="Unsupervised feature transformation via in-context generation, generator-critic llm agents, and duet-play teaming" class="publication-image teaser" onerror="this.src='images/default-paper.png'">
                    <div class="publication-content">
                        <p class="publication-title"><span class="publication-venue">IJCAI'25</span> Unsupervised feature transformation via in-context generation, generator-critic llm agents, and duet-play teaming</p>
                        <p class="publication-authors">Nanxu Gong, Xinyuan Wang, Wangyang Ying, Haoyue Bai, <span class="author-highlight">Sixun Dong</span>, Haifeng Chen, Yanjie Fu</p>
                        <p class="publication-links"><i class="ai ai-arxiv"></i> <a href="https://arxiv.org/abs/2504.21304" target="_blank">Paper</a> / <i class="fab fa-github"></i> <a href="https://github.com/NanxuGong/LPFG" target="_blank">Code</a></p>
                    </div>
                </div>
                </div>
            </div>
            <div class="year-group">
                <h3 class="year-title">2024</h3>
                <div class="publications-list">
                    
                <div class="publication-item">
                    <img src="teaser/mmtool.jpg" alt="MLLM-Tool: A Multimodal Large Language Model For Tool Agent Learning" class="publication-image teaser" onerror="this.src='images/default-paper.png'">
                    <div class="publication-content">
                        <p class="publication-title"><span class="publication-venue">WACV'25</span> MLLM-Tool: A Multimodal Large Language Model For Tool Agent Learning</p>
                        <p class="publication-authors">Chenyu Wang, Weixin Luo, <span class="author-highlight">Sixun Dong</span>, Xiaohua Xuan, Zhengxin Li, Lin Ma, Shenghua Gao</p>
                        <p class="publication-links"><i class="ai ai-arxiv"></i> <a href="https://arxiv.org/abs/2401.10727" target="_blank">Paper</a> / <i class="fab fa-github"></i> <a href="https://github.com/MLLM-Tool/MLLM-Tool" target="_blank">Code</a></p>
                    </div>
                </div>
                <div class="publication-item">
                    <img src="teaser/room.jpg" alt="RoomDesigner: Encoding Anchor-latents for Style-consistent and Shape-compatible Indoor Scene Generation" class="publication-image teaser" onerror="this.src='images/default-paper.png'">
                    <div class="publication-content">
                        <p class="publication-title"><span class="publication-venue">3DV'24</span> RoomDesigner: Encoding Anchor-latents for Style-consistent and Shape-compatible Indoor Scene Generation</p>
                        <p class="publication-authors">Yiqun Zhao, Zibo Zhao, Jing Li, <span class="author-highlight">Sixun Dong</span>, Shenghua Gao</p>
                        <p class="publication-links"><i class="ai ai-arxiv"></i> <a href="https://arxiv.org/abs/2310.10027" target="_blank">Paper</a> / <i class="fab fa-github"></i> <a href="https://github.com/zhao-yiqun/RoomDesigner" target="_blank">Code</a></p>
                    </div>
                </div>
                </div>
            </div>
            <div class="year-group">
                <h3 class="year-title">2023</h3>
                <div class="publications-list">
                    
                <div class="publication-item">
                    <img src="teaser/weaksvr.jpg" alt="Weakly Supervised Video Representation Learning with Unaligned Text for Sequential Videos" class="publication-image teaser" onerror="this.src='images/default-paper.png'">
                    <div class="publication-content">
                        <p class="publication-title"><span class="publication-venue">CVPR'23</span> Weakly Supervised Video Representation Learning with Unaligned Text for Sequential Videos</p>
                        <p class="publication-authors"><span class="author-highlight">Sixun Dong*</span>, Huazhang Hu*, Dongze Lian, Weixin Luo, Yicheng Qian, Shenghua Gao</p>
                        <p class="publication-links"><i class="ai ai-arxiv"></i> <a href="https://arxiv.org/abs/2303.12370" target="_blank">Paper</a> / <i class="fab fa-github"></i> <a href="https://github.com/svip-lab/WeakSVR" target="_blank">Code</a> / <i class="fab fa-youtube"></i> <a href="https://www.youtube.com/watch?v=AqozSRYP7Pc" target="_blank">YouTube</a> / <i class="fas fa-tv"></i> <a href="https://www.bilibili.com/video/BV1AW4y1R7um" target="_blank">Bilibili</a> / <i class="fas fa-book-open"></i> <a href="https://zhuanlan.zhihu.com/p/617926257" target="_blank">Áü•‰πé</a></p>
                    </div>
                </div>
                </div>
            </div>
            <div class="year-group">
                <h3 class="year-title">2022</h3>
                <div class="publications-list">
                    
                <div class="publication-item">
                    <img src="teaser/transrac.jpg" alt="TransRAC: Encoding Multi-scale Temporal Correlation with Transformers for Repetitive Action Counting" class="publication-image teaser" onerror="this.src='images/default-paper.png'">
                    <div class="publication-content">
                        <p class="publication-title"><span class="publication-venue">CVPR'22</span><span class="publication-venue-oral">üèÜ Oral</span> TransRAC: Encoding Multi-scale Temporal Correlation with Transformers for Repetitive Action Counting</p>
                        <p class="publication-authors">Huazhang Hu*, <span class="author-highlight">Sixun Dong*</span>, Yiqun Zhao, Dongze Lian, Zhengxin Li, Shenghua Gao</p>
                        <p class="publication-links"><i class="ai ai-arxiv"></i> <a href="https://arxiv.org/abs/2204.01018" target="_blank">Paper</a> / <i class="fab fa-github"></i> <a href="https://github.com/SvipRepetitionCounting/TransRAC" target="_blank">Code</a> / <i class="fas fa-database"></i> <a href="https://svip-lab.github.io/dataset/RepCount_dataset.html" target="_blank">Dataset</a> / <i class="fab fa-youtube"></i> <a href="https://youtu.be/SFpUS9mHHpk" target="_blank">YouTube</a> / <i class="fas fa-tv"></i> <a href="https://www.bilibili.com/video/BV1B94y1S7oP" target="_blank">Bilibili</a> / <i class="fas fa-book-open"></i> <a href="https://zhuanlan.zhihu.com/p/543376943" target="_blank">Áü•‰πé</a></p>
                    </div>
                </div>
                </div>
            </div>
            <div class="year-group">
                <h3 class="year-title">Survey Papers</h3>
                <div class="publications-list">
                    
                <div class="publication-item">
                    <img src="teaser/underreview.jpg" alt="Towards Data-Centric AI: A Comprehensive Survey of Traditional, Reinforcement, and Generative Approaches for Tabular Data Transformation" class="publication-image teaser" onerror="this.src='images/default-paper.png'">
                    <div class="publication-content">
                        <p class="publication-title"><span class="publication-venue-under-review">arXiv'2501</span> Towards Data-Centric AI: A Comprehensive Survey of Traditional, Reinforcement, and Generative Approaches for Tabular Data Transformation</p>
                        <p class="publication-authors">Dongjie Wang, Yanyong Huang, Wangyang Ying, Haoyue Bai, Nanxu Gong, Xinyuan Wang, <span class="author-highlight">Sixun Dong</span>, Tao Zhe, Kunpeng Liu, Meng Xiao, et al.</p>
                        <p class="publication-links"><i class="ai ai-arxiv"></i> <a href="https://arxiv.org/abs/2501.10555" target="_blank">Paper</a></p>
                    </div>
                </div>
                <div class="publication-item">
                    <img src="teaser/underreview.jpg" alt="A Survey on Data-Centric AI: Tabular Learning from Reinforcement Learning and Generative AI Perspective" class="publication-image teaser" onerror="this.src='images/default-paper.png'">
                    <div class="publication-content">
                        <p class="publication-title"><span class="publication-venue-under-review">arXiv'2502</span> A Survey on Data-Centric AI: Tabular Learning from Reinforcement Learning and Generative AI Perspective</p>
                        <p class="publication-authors">Wangyang Ying, Cong Wei, Nanxu Gong, Xinyuan Wang, Haoyue Bai, Arun Vignesh Malarkkan, <span class="author-highlight">Sixun Dong</span>, Dongjie Wang, Denghui Zhang, Yanjie Fu</p>
                        <p class="publication-links"><i class="ai ai-arxiv"></i> <a href="https://arxiv.org/abs/2502.08828" target="_blank">Paper</a></p>
                    </div>
                </div>
                </div>
            </div>
            <div class="year-group">
                <h3 class="year-title">Other Publications <span class="auto-sync-note">Auto-updated based on Google Scholar (Last synced: Oct 6, 2025)</span></h3>
                <div class="publications-list">
                    
                <div class="publication-item">
                    <img src="teaser/preprint.jpg" alt="LLM-ML Teaming: Integrated Symbolic Decoding and Gradient Search for Valid and Stable Generative Feature Transformation" class="publication-image teaser" onerror="this.src='images/default-paper.png'">
                    <div class="publication-content">
                        <p class="publication-title"><span class="publication-venue-preprint">arXiv'2506</span> LLM-ML Teaming: Integrated Symbolic Decoding and Gradient Search for Valid and Stable Generative Feature Transformation</p>
                        <p class="publication-authors">Xinyuan Wang, Haoyue Bai, Nanxu Gong, Wangyang Ying, <span class="author-highlight">Sixun Dong</span>, X Cui, Yanjie Fu</p>
                        <p class="publication-links"><i class="ai ai-arxiv"></i> <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=j71Y2-4AAAAJ&sortby=pubdate&citation_for_view=j71Y2-4AAAAJ:_FxGoFyzp5QC" target="_blank">Paper</a></p>
                    </div>
                </div>
                <div class="publication-item">
                    <img src="teaser/preprint.jpg" alt="Efficient Post-Training Refinement of Latent Reasoning in Large Language Models" class="publication-image teaser" onerror="this.src='images/default-paper.png'">
                    <div class="publication-content">
                        <p class="publication-title"><span class="publication-venue-preprint">arXiv'2506</span> Efficient Post-Training Refinement of Latent Reasoning in Large Language Models</p>
                        <p class="publication-authors">Xinyuan Wang, Dongjie Wang, Wangyang Ying, Haoyue Bai, Nanxu Gong, <span class="author-highlight">Sixun Dong</span>, Kunpeng Liu, Yanjie Fu</p>
                        <p class="publication-links"><i class="ai ai-arxiv"></i> <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=j71Y2-4AAAAJ&sortby=pubdate&citation_for_view=j71Y2-4AAAAJ:ufrVoPGSRksC" target="_blank">Paper</a></p>
                    </div>
                </div>
                <div class="publication-item">
                    <img src="teaser/preprint.jpg" alt="Brownian Bridge Augmented Surrogate Simulation and Injection Planning for Geological CO Storage" class="publication-image teaser" onerror="this.src='images/default-paper.png'">
                    <div class="publication-content">
                        <p class="publication-title"><span class="publication-venue-preprint">arXiv'2505</span> Brownian Bridge Augmented Surrogate Simulation and Injection Planning for Geological CO Storage</p>
                        <p class="publication-authors">Haoyue Bai, G Chen, Wangyang Ying, Xinyuan Wang, Nanxu Gong, <span class="author-highlight">Sixun Dong</span>, G Pedrielli, H Wang, ...</p>
                        <p class="publication-links"><i class="ai ai-arxiv"></i> <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=j71Y2-4AAAAJ&sortby=pubdate&citation_for_view=j71Y2-4AAAAJ:WF5omc3nYNoC" target="_blank">Paper</a></p>
                    </div>
                </div>
                <div class="publication-item">
                    <img src="teaser/preprint.jpg" alt="Bridging the domain gap in equation distillation with reinforcement feedback" class="publication-image teaser" onerror="this.src='images/default-paper.png'">
                    <div class="publication-content">
                        <p class="publication-title"><span class="publication-venue-preprint">arXiv'2505</span> Bridging the domain gap in equation distillation with reinforcement feedback</p>
                        <p class="publication-authors">Wangyang Ying, Haoyue Bai, Nanxu Gong, Xinyuan Wang, <span class="author-highlight">Sixun Dong</span>, H Chen, Yanjie Fu</p>
                        <p class="publication-links"><i class="ai ai-arxiv"></i> <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=j71Y2-4AAAAJ&sortby=pubdate&citation_for_view=j71Y2-4AAAAJ:eQOLeE2rZwMC" target="_blank">Paper</a></p>
                    </div>
                </div>
                </div>
            </div>
            </div>
        </section>
    </main>

    
    <footer class="footer">
        <div class="container">
            <!-- Visitor Map Section -->
            <div class="visitor-map-section">
                <div class="visitor-map-container">
                    <!-- Visitor Map Widget -->
                    <div class="visitor-map">
                        <!-- ClustrMaps Widget -->
                        <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=r_cMMykDPAdqK2GTahWbR__mtnzcj9svUgejZ86OXnU&cl=ffffff&w=a"></script>
                    </div>
                </div>
            </div>

            <div class="footer-stats">
                <div class="stats-item">
                    <i class="fas fa-map-marker-alt"></i>
                    Last updated from: <span id="owner-location">Loading...</span>
                </div>
                <div class="stats-item">
                    <i class="fas fa-clock"></i>
                    Content last updated: <span id="last-updated"></span>
                </div>
            </div>
            
            <div class="template-credit">
                <p>Built with <a href="https://github.com/Ironieser/ironieser.github.io" target="_blank" rel="noopener">Config-Driven Academic Website Template</a> by <a href="https://github.com/Ironieser/ironieser.github.io" target="_blank" rel="noopener">Sixun Dong (ironieser)</a></p>
                <p class="template-acknowledgments">Built with the help of Cursor IDE, Claude AI, and GPT - enabling non-experts to create personalized academic websites through modern AI tools</p>
            </div>
            <p>&copy; 2025 Sixun Dong. All rights reserved.</p>
        </div>
    </footer>
    
    
    <script>
        // Get website owner's location during build (not visitor's location)
        async function getOwnerLocation() {
            try {
                // Try primary API first
                let response = await fetch('https://ipapi.co/json/');
                let data = await response.json();
                
                if (data.city && data.country_name) {
                    const location = `${data.city}, ${data.country_name}`;
                    document.getElementById('owner-location').textContent = location;
                    return;
                }
                
                // If primary API fails, try backup API
                response = await fetch('https://api.ipify.org?format=json');
                const ipData = await response.json();
                
                if (ipData.ip) {
                    // Use a different geolocation service
                    response = await fetch(`https://ip-api.com/json/${ipData.ip}`);
                    data = await response.json();
                    
                    if (data.city && data.country) {
                        const location = `${data.city}, ${data.country}`
                        document.getElementById('owner-location').textContent = location;
                        return;
                    }
                }
                
                // If all APIs fail, show a default message
                document.getElementById('owner-location').textContent = 'Remote Server';
                
            } catch (error) {
                console.log('Location detection failed:', error);
                // For GitHub Actions builds, show a more appropriate message
                document.getElementById('owner-location').textContent = 'GitHub Actions';
            }
        }
        
        // Set last updated time (when GitHub Actions built the site)
        function setLastUpdated() {
            const buildDate = '2025-10-12';
            const date = new Date(buildDate + 'T12:00:00'); // Add noon time to avoid timezone issues
            const formatted = date.toLocaleDateString('en-US', { 
                year: 'numeric', 
                month: 'short', 
                day: 'numeric' 
            });
            document.getElementById('last-updated').textContent = formatted;
        }
        
        // Initialize on page load
        document.addEventListener('DOMContentLoaded', function() {
            getOwnerLocation();
            setLastUpdated();
        });
    </script>
</body>
</html>