// Auto-generated blog data
// This file is automatically updated by build scripts
// Do not edit manually

window.BLOG_DATA = [
  {
    "id": "timesclip-time-series-forecasting",
    "filename": "timesclip-time-series-forecasting.md",
    "title": "Long-term/Short-term Time Series Forecasting: TimesCLIP ‚Äî CLIP is ALL you NEED",
    "date": "2025-08-07",
    "formattedDate": "August 07, 2025",
    "description": "My first PhD work on applying vision-language contrastive learning (CLIP) to time series forecasting. As far as I know, this is the first work to bring multimodal contrastive learning to time series forecasting. The method is extremely simple but surprisingly effective.",
    "tags": [
      "Time Series",
      "CLIP",
      "Multimodal Learning",
      "Deep Learning",
      "PhD Research"
    ],
    "image": "images/blog/timesclip/fig3.png",
    "content": "<h1>Long-term/Short-term Time Series Forecasting: TimesCLIP ‚Äî CLIP is ALL you NEED</h1>\n\n<p>> _Let me take this chance to shamelessly promote my first PhD work ‚Äî my debut attempt in time series forecasting. I hope folks here can cut me some slack! As far as I know, this is the first work to apply vision-language contrastive learning (√† la CLIP) to time series forecasting. The method is extremely simple but surprisingly effective._</p>\n\n---\n\n<h2>TL;DR</h2>\n\n<strong>CLIP is ALL you NEED</strong>  \n<p>Just replace those painfully hand-tuned transformer layers with <strong>CLIP-TEXT</strong> and you'll set a new SoTA on 16 short-term forecasting datasets.  </p>\n<p>Stack our proposed multimodal framework (following CLIP, CoCa[1]) and performance jumps even higher.  </p>\n<p>Our hypothesis: <strong>CLIP-Text aligns multimodal space and captures both numerical and visual patterns in time series</strong>.  </p>\n<p>_Code coming soon (internship season‚Ä¶ overloaded (T–¥T))_</p>\n\n<p>> <strong>Seriously, CLIP-Text as backbone is OP. Hahaha (T–¥T)</strong></p>\n\n<ul>\n<li><strong>Paper Title:</strong> _Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives_  </li>\n<li><strong>ArXiv:</strong> <a href=\"https://arxiv.org/pdf/2506.24124\">PDF</a></li>\n<li><strong>GitHub:</strong> <a href=\"https://github.com/Ironieser/TimesCLIP\">Ironieser/TimesCLIP</a> _(GitHub stars welcome, first to release after open source(„Éªœâ„Éª) )_</li>\n</ul>\n\n---\n\n<h2>1. Core Motivation</h2>\n\n<p>Existing Transformer-based time series models have <strong>two major flaws</strong>:</p>\n\n<h3>(1) Hyperparameter over-tuning destroys scalability</h3>\n\n<p>Many transformer models only perform well with tons of parameter searching ‚Äî but this ruins scalability and destroys the <em>very spirit</em> of Transformer: <strong>no model surgery needed, just stack more layers (ViT-S, ViT-B, ViT-L) and you're good</strong>.</p>\n\n<h3>(2) Single modality limitation</h3>\n\n<p>All existing forecasting is based <em>purely</em> on numerical input. In reality, professionals (hello stock traders!) rely heavily on <strong>visual patterns (trends)</strong> to predict future changes.</p>\n\n---\n\n<strong>Our corresponding solutions:</strong>\n\n<ol>\n<li><strong>Find a suitable pretrained model as backbone, then don't touch the model structure ‚Üí <code>CLIP is ALL you NEED</code></strong></li>\n<li><strong>Explore how to apply visual priors to time series forecasting ‚Üí <code>Multimodal Contrastive Learning is ALL you NEED</code></strong></li>\n</ol>\n\n<img src=\"images/blog/timesclip/fig1.png\" alt=\"TimesCLIP Motivation\" style=\"width: 60%; max-width: 600px; height: auto; display: block; margin: 0 auto;\">\n\n<em>Figure 1: Core motivation - existing transformer models suffer from hyperparameter over-tuning and single modality limitations</em>\n\n<img src=\"images/blog/timesclip/fig2.png\" alt=\"Visual Pattern Recognition\" style=\"width: 60%; max-width: 600px; height: auto; display: block; margin: 0 auto;\">\n\n<em>Figure 2: Comparison of existing methods vs. our multimodal approach - bridging numerical and visual understanding</em>\n\n---\n\n<h2>2. The Proposed Model: TimesCLIP</h2>\n\n<p>Following the motivation above, we try different models (CLIP, BERT, GPT-2, T5) as backbone and apply the multimodal contrastive learning framework to time series forecasting.</p>\n\n<h3>üß™ <strong>The experimental results are extremely surprising:</strong></h3>\n\n<ol>\n<li><strong>Simply using CLIP-Text as backbone, replacing iTransformer or PatchTST's Encoder (i.e., all those hand-crafted transformer layers), achieves better performance.</strong></li>\n</ol>\n\n<ol>\n<li><strong>Additionally, we also reference CoCa's framework (from 2022, still ImageNet SoTA in 2025 I think), applying CLIP-style image-text contrastive learning framework to time series forecasting, with extremely significant results.</strong></li>\n</ol>\n\n<p>But two issues still need to be resolved:</p>\n\n<ul>\n<li><strong>Multivariate forecasting:</strong> Dependencies exist between variables, or for univariate prediction, intra-variable dependencies are extremely strong. iTransformer only focuses on inter-variable relations, while PatchTST only focuses on intra-variable relations.</li>\n<li><strong>How to better convert time series to images?</strong> Numerical line plots? Spectrograms?</li>\n</ul>\n\n<img src=\"images/blog/timesclip/fig3.png\" alt=\"TimesCLIP Architecture\" style=\"width: 80%; max-width: 800px; height: auto; display: block; margin: 0 auto;\">\n\n<em>Figure 3: Our proposed TimesCLIP framework - multimodal contrastive learning for time series forecasting</em>\n\n---\n\n<h4><strong>For these, we propose two solutions:</strong></h4>\n\n<strong>1. For intra-variable and inter-variable relations:</strong>  \n<p>We believe intra-variable is more important than inter-variable, so the backbone follows PatchTST-style. But inter-variable relations are also needed, so we designed a <strong>Variate Selection</strong> module, introducing learnable variable feature [CLS] tokens, constrained through visual and language contrastive learning, to find relevant variables from inter-variable relations as supplements to guide final generation.</p>\n\n<strong>2. On time series to image conversion:</strong>  \n<p>Experience easily shows that existing vision models' training data comes from the internet, obviously unable to handle spectrograms well, while <strong>line plots have abundant training data</strong> (English exam chart description tasks). And LLMs like GPT obviously understand line charts, so we directly convert numerical values to line plots.</p>\n\n<p>Furthermore, since numerical differences between different variables are large, we additionally use <strong>z-score normalization (max-min normalize)</strong> to separately adjust each variable to have reasonable numerical ranges. On the other hand, we use <strong>different colors for each variable</strong>, ensuring variables have the same shape while allowing the vision encoder to distinguish variables from different sources through color.</p>\n\n<img src=\"images/blog/timesclip/fig4.png\" alt=\"Time Series Visualization\" style=\"width: 60%; max-width: 600px; height: auto; display: block; margin: 0 auto;\">\n\n<em>Figure 4: Visualization of time series to image conversion with different colors for each variable</em>\n\n<p>At this point, our method design is complete.</p>\n\n---\n\n<h2>3. Important Experimental Results</h2>\n\n<h3>3.1 Short-term Forecasting</h3>\n\n<p>Experimental results show: <strong>completely no need to change any model structure or training parameters</strong>, can be widely applied to 22 datasets, especially for short-term forecasting performance which is extremely robust (evaluated on 16 short-term forecasting datasets).</p>\n\n<p>Additionally, our method has significantly better performance than Time-VLM[2] (accepted by ICML 2025). (<strong>Pure CLIP-Text alone already outperforms Time-VLM on M4</strong> (*¬¥‚àÄÔΩÄ))</p>\n\n\n<p>!<a href=\"images/blog/timesclip/fig5.png\">Short-term Forecasting Results</a></p>\n<em>Figure 5: Short-term forecasting results - TimesCLIP achieves SoTA on 16 datasets</em>\n\n<img src=\"images/blog/timesclip/fig6.png\" alt=\"Training Configuration\" style=\"width: 60%; max-width: 600px; height: auto; display: block; margin: 0 auto;\">\n\n<em>Figure 6: Training configuration details - EarlyStop and Train Epochs are casually set, LR uses empirical parameters, batch size is limited by GPU memory</em>\n\n\n\n\n<h3>3.2 Long-term Forecasting</h3>\n\n<p>TimesCLIP achieved decent performance on 6 datasets (Exchange, Traffic, Weather, ETTm1, ETTm2, Solar Energy).</p>\n\n<p>> <strong>Note:</strong> We intentionally removed all 96 ‚Üí 336,720 experimental results. Although we have more obvious performance advantages in such settings, we also follow Dr. Christoph Bergmeir's viewpoint in his NeurIPS 2024 talk <a href=\"https://cbergmeir.com/talks/neurips2024/\">_\"Fundamental limitations of foundational forecasting models: The need for multimodality and rigorous evaluation\"_</a> that <strong>such experimental settings are completely meaningless</strong>.</p>\n<p>> </p>\n<p>> For example: using 16 hours of data to predict 5 days of weather, using past 4 days of traffic to predict next 30 days, makes absolutely no sense... And the variance and mean are both greater than 0.5... This is prediction after normalization...</p>\n<p>> </p>\n<p>> Currently under review, hoping reviewers and ACs can agree with Dr. Christoph Bergmeir's viewpoint and recognize our experiments hahaha (currently not recognized (ÔΩ°>Ôπè<ÔΩ°))</p>\n<p>> </p>\n<p>> <strong>Highly recommend Dr. Christoph Bergmeir's talk</strong> - I strongly agree with his points about model issues, dataset problems, and experimental setting concerns in time series forecasting.</p>\n\n<p>!<a href=\"images/blog/timesclip/fig7.png\">Long-term Forecasting Results</a></p>\n<em>Figure 7: Long-term forecasting performance on 6 datasets</em> \n\n<h3>3.3 Ablation Studies</h3>\n\n<p>We conducted experiments with comprehensive permutations to verify:</p>\n<ol>\n<li>Giving different colors to variables</li>\n<li>Variate selection module (capturing inter-variable relations)  </li>\n<li>Multimodal contrastive learning</li>\n</ol>\n\n<p>We also tested all permutations of different vision backbones and language backbones for performance impact. An interesting result is <strong>ViT performs better than CLIP-ViT</strong>. We speculate this is due to large domain differences - the visual model is only used to extract patterns, whether it's pre-aligned with language models may not be that important.</p>\n\n<p>But <strong>CLIP-Text is really useful!</strong> Its feature space might be multimodal, simultaneously having both language and vision characteristics.</p>\n\n<p>Also, pure vision doesn't work, which should be easy to know from experience. But surprisingly, GPT-2 also doesn't work, perhaps aligning to some degree with the viewpoint in <a href=\"https://arxiv.org/abs/2406.16964\">Are Language Models Actually Useful for Time Series Forecasting?</a>. Simple LMs might not work, but T5 performs okay - is it because of parameter count? This work only wants to explore multimodality, so deeper analysis is left for the future.</p>\n\n<img src=\"images/blog/timesclip/fig8.png\" alt=\"Ablation Study Results\" style=\"width: 60%; max-width: 600px; height: auto; display: block; margin: 0 auto;\">\n\n<em>Figure 8: Ablation study results showing the impact of different components</em>\n\n<img src=\"images/blog/timesclip/fig9.png\" alt=\"Backbone Comparison\" style=\"width: 60%; max-width: 600px; height: auto; display: block; margin: 0 auto;\">\n\n<em>Figure 9: Comparison of different vision and language backbones - CLIP-Text shows superior performance</em>\n\n---\n\n<h2>4. Final Thoughts</h2>\n\n<p>Hope this work can bring some insights to everyone, including:</p>\n\n<ol>\n<li><strong>Multimodality is really useful for time series</strong></li>\n<li><strong>CLIP-Text is really useful</strong>  </li>\n<li><strong>Think carefully about the significance of long-term forecasting under TimesNet, iTransformer... be cautious about following... be cautious</strong></li>\n</ol>\n\n---\n\n<h2>5. Method Limitations and Future Work</h2>\n\n<h3>5.1 Method Limitations</h3>\n\n<p>Of course can't forget to tell everyone about current limitations, roughly three points:</p>\n\n<ol>\n<li><strong>Poor performance on classification</strong>, severe overfitting, perhaps because TimesNet's classification datasets are really too small (some datasets only 120 samples...)</li>\n</ol>\n\n<ol>\n<li><strong>Obviously much slower training speed compared to hand-crafted formers</strong>, could try LoRA</li>\n</ol>\n\n<ol>\n<li><strong>Currently doesn't consider how to handle multivariate and long input</strong>, causes OOM. Future work could explore better tokenizer design, but I completely don't recommend any model modification behavior... If using Transformer, please fix the model structure...</li>\n</ol>\n\n<h3>5.2 Future Work</h3>\n\n<ol>\n<li><strong>Combining with VLMs</strong>: Like LLaVA's vision tower is inherently based on CLIP, integrating this work's framework with VLMs would be very natural. Could also try time series to text, but datasets might be key.</li>\n</ol>\n\n<ol>\n<li><strong>Anomaly Detection</strong>: Time series visual patterns are really perfect for anomaly detection.</li>\n</ol>\n\n---\n\n<h2>References</h2>\n\n<ul>\n<li><strong>Paper:</strong> <a href=\"https://arxiv.org/pdf/2506.24124\">Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives</a></li>\n<li><strong>Personal Homepage:</strong> <a href=\"https://cv.ironieser.cc/\">Sixun Dong - Academic Homepage</a></li>\n</ul>\n\n<h3>References</h3>\n<p>[1] CoCa: Contrastive Captioners are Image-Text Foundation Models https://arxiv.org/abs/2205.01917  </p>\n<p>[2] Time-VLM: Exploring Multimodal Vision-Language Models for Augmented Time Series Forecasting https://arxiv.org/abs/2502.04395</p>\n\n---\n\n<h2>Citation</h2>\n\n<p>If you find this work useful, please consider citing:</p>\n\n<p><pre><code class=\"language-bibtex\">@article{sixun2025teaching,</p>\n<p>  title={Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives},</p>\n<p>  author={Sixun, Dong and Wei, Fan and Wu, Teresa and Yanjie, Fu},</p>\n<p>  journal={arXiv preprint arXiv:2506.24124},</p>\n<p>  year={2025}</p>\n<p>}</code></pre></p>\n\n---\n\n<p><strong>Finally, welcome any questions, any discussions, and any criticism of this work!</strong> üöÄ </p>",
    "metadata": {
      "title": "Long-term/Short-term Time Series Forecasting: TimesCLIP ‚Äî CLIP is ALL you NEED",
      "date": "2025-08-07",
      "description": "My first PhD work on applying vision-language contrastive learning (CLIP) to time series forecasting. As far as I know, this is the first work to bring multimodal contrastive learning to time series forecasting. The method is extremely simple but surprisingly effective.",
      "tags": [
        "Time Series",
        "CLIP",
        "Multimodal Learning",
        "Deep Learning",
        "PhD Research"
      ],
      "image": "images/blog/timesclip/fig3.png"
    }
  },
  {
    "id": "introducing-config-driven-academic-website-template",
    "filename": "introducing-config-driven-academic-website-template.md",
    "title": "My Config-Driven Academic Website Template",
    "date": "2025-06-27",
    "formattedDate": "June 27, 2025",
    "description": "How I built a simple system to manage my academic website using JSON configuration and GitHub Actions.",
    "tags": [
      "Academic Website",
      "GitHub Actions",
      "Template",
      "Web Development"
    ],
    "image": "teaser/preprint.jpg",
    "content": "<h1>My Config-Driven Academic Website Template</h1>\n\n<p>I got tired of manually editing HTML files every time I wanted to update my academic website, so I built a simple system that lets me manage everything through a JSON configuration file.</p>\n\n<h2>The Problem I Had</h2>\n\n<p>Like many academics, I struggled with:</p>\n<ul>\n<li>Editing HTML files for every publication update</li>\n<li>Keeping formatting consistent across pages</li>\n<li>Worrying about breaking the layout</li>\n<li>Spending time on code instead of content</li>\n</ul>\n\n<h2>My Solution</h2>\n\n<p>I created a system where all my content lives in a single <code>config.json</code> file, and GitHub Actions automatically generates the HTML pages.</p>\n\n<h3>Before and After</h3>\n\n<p><strong>Before</strong>: Editing HTML directly</p>\n<pre><code class=\"language-html\"><div class=\"publication-item\">\n  <img src=\"teaser/my-paper.jpg\" alt=\"My Paper\">\n  <div class=\"publication-content\">\n    <p class=\"publication-title\">My Research Paper</p>\n    <!-- lots more HTML... -->\n  </div>\n</div></code></pre>\n\n<p><strong>After</strong>: Simple JSON structure</p>\n<p><pre><code class=\"language-json\">{</p>\n<p>  \"title\": \"My Research Paper\",</p>\n<p>  \"authors\": [\"Sixun Dong\", \"Collaborators\"],</p>\n<p>  \"venue\": \"CVPR 2025\",</p>\n<p>  \"image\": \"teaser/my-paper.jpg\",</p>\n<p>  \"links\": [{\"name\": \"Paper\", \"url\": \"https://...\"}]</p>\n<p>}</code></pre></p>\n\n<h2>How It Works</h2>\n\n<ol>\n<li><strong>Edit config.json</strong> with your content</li>\n<li><strong>Push to GitHub</strong> </li>\n<li><strong>GitHub Actions</strong> runs and generates HTML</li>\n<li><strong>Website updates</strong> automatically</li>\n</ol>\n\n<p>The build process uses Node.js scripts that read the JSON and generate HTML using templates.</p>\n\n<h2>Key Features</h2>\n\n<h3>Single Configuration File</h3>\n<p>Everything lives in <code>config.json</code>:</p>\n<ul>\n<li>Personal info and bio</li>\n<li>Publications by year</li>\n<li>News updates</li>\n<li>Experience and education</li>\n</ul>\n\n<h3>Automatic HTML Generation</h3>\n<p>GitHub Actions detects changes to the config and rebuilds the site automatically.</p>\n\n<h3>Blog System</h3>\n<p>Blog posts are written in Markdown with frontmatter:</p>\n<p><pre><code class=\"language-markdown\">---</p>\n<p>title: \"Post Title\"</p>\n<p>date: \"2025-01-01\"</p>\n<p>description: \"Brief description\"</p>\n<p>tags: [\"Tag1\", \"Tag2\"]</p>\n---\n\n<h1>Your content here...</h1></code></pre>\n\n<h3>Publication Management</h3>\n<p>Publications are organized by year with support for:</p>\n<ul>\n<li>Different venue types (conference, journal, under review)</li>\n<li>Featured publications that appear on homepage</li>\n<li>Multiple links (paper, code, dataset, etc.)</li>\n<li>Automatic author name highlighting</li>\n</ul>\n\n<h2>Technical Implementation</h2>\n\n<p>The system consists of:</p>\n<ul>\n<li><strong>Build scripts</strong> (Node.js) that process the JSON config</li>\n<li><strong>HTML templates</strong> for different page types</li>\n<li><strong>GitHub Actions workflow</strong> for automation</li>\n<li><strong>Simple CSS/JS</strong> for styling and interactions</li>\n</ul>\n\n<h3>Local Development</h3>\n<p>You can build and preview locally:</p>\n<p><pre><code class=\"language-bash\">python build_local.py  # Generate HTML</p>\n<p>python local_server.py # Start local server</code></pre></p>\n\n<h2>What I Learned</h2>\n\n<p>Building this taught me:</p>\n<ul>\n<li>GitHub Actions is quite powerful for automation</li>\n<li>JSON is a good format for structured academic content</li>\n<li>Simple solutions often work better than complex ones</li>\n<li>Documentation matters (I should write more)</li>\n</ul>\n\n<h2>Current Status</h2>\n\n<p>The template works well for my needs, but it's still evolving. I add features as I need them:</p>\n<ul>\n<li>‚úÖ Basic publication management</li>\n<li>‚úÖ Blog system with Markdown</li>\n<li>‚úÖ Automated deployment</li>\n<li>‚úÖ Comment system (Waline)</li>\n<li>‚úÖ Favicon support</li>\n<li>üîÑ Better mobile experience</li>\n<li>üîÑ More customization options</li>\n</ul>\n\n<h2>Using This Template</h2>\n\n<p>If you want to use this for your own site:</p>\n\n<ol>\n<li><strong>Fork</strong> the repository</li>\n<li><strong>Edit</strong> <code>config.json</code> with your information</li>\n<li><strong>Enable</strong> GitHub Pages in repository settings</li>\n<li><strong>Push</strong> changes to trigger the build</li>\n</ol>\n\n<p>The source code is available on GitHub. It's not the most polished system, but it works for my needs and might be useful for others.</p>\n\n<h2>Limitations</h2>\n\n<p>This approach has some downsides:</p>\n<ul>\n<li>Requires basic Git/GitHub knowledge</li>\n<li>Limited customization without editing code</li>\n<li>Build process can be slow for large sites</li>\n<li>No real-time preview (need to push to see changes)</li>\n</ul>\n\n<h2>Future Ideas</h2>\n\n<p>Things I might add:</p>\n<ul>\n<li>Better theme customization</li>\n<li>More publication types</li>\n<li>Integration with citation managers</li>\n<li>Mobile app for quick updates</li>\n<li>Better documentation</li>\n</ul>\n\n<h2>Conclusion</h2>\n\n<p>This system solved my specific problem of maintaining an academic website without dealing with HTML. It's not perfect, but it's much easier than manually editing files.</p>\n\n<p>If you're interested in trying it out or have suggestions for improvements, feel free to check out the code or reach out.</p>\n\n---\n\n<em>This is just my personal solution to a common problem. Your mileage may vary.</em> ",
    "metadata": {
      "title": "My Config-Driven Academic Website Template",
      "date": "2025-06-27",
      "description": "How I built a simple system to manage my academic website using JSON configuration and GitHub Actions.",
      "tags": [
        "Academic Website",
        "GitHub Actions",
        "Template",
        "Web Development"
      ],
      "image": "teaser/preprint.jpg"
    }
  },
  {
    "id": "homepage-introduction",
    "filename": "homepage-introduction.md",
    "title": "Welcome to My Academic Homepage",
    "date": "2025-06-26",
    "formattedDate": "June 26, 2025",
    "description": "A brief introduction to my academic homepage and how it's organized to showcase my research work.",
    "tags": [
      "Homepage",
      "Academic",
      "Research"
    ],
    "image": "teaser/preprint.jpg",
    "content": "<h1>Welcome to My Academic Homepage</h1>\n\n<p>Welcome to my academic homepage! This site showcases my research work, publications, and thoughts on computer vision and AI.</p>\n\n<h2>What You'll Find Here</h2>\n\n<h3>üè† <strong>About Me</strong></h3>\n<p>The main page has my current position, research interests, and recent news. I'm a PhD student at Arizona State University working on multimodal AI systems.</p>\n\n<h3>üìö <strong>Publications</strong></h3>\n<p>A collection of my research papers organized by year, including:</p>\n<ul>\n<li>Conference and journal papers</li>\n<li>Links to papers, code, and datasets</li>\n<li>Brief descriptions and visual previews</li>\n</ul>\n\n<h3>üìù <strong>Blog</strong></h3>\n<p>Occasional posts about:</p>\n<ul>\n<li>Research insights and experiences</li>\n<li>Technical notes and tutorials</li>\n<li>Thoughts on AI and computer vision</li>\n</ul>\n\n<h2>How This Site Works</h2>\n\n<p>This website is built using a config-driven approach that I developed:</p>\n\n<h3>‚öôÔ∏è <strong>Configuration-Based</strong></h3>\n<ul>\n<li>All content is managed through a single <code>config.json</code> file</li>\n<li>Publications, news, and personal info are all in structured data</li>\n<li>Makes it easy to update without editing HTML</li>\n</ul>\n\n<h3>ü§ñ <strong>Automated Building</strong></h3>\n<ul>\n<li>GitHub Actions automatically generates HTML from the config</li>\n<li>Blog posts are written in Markdown and processed automatically</li>\n<li>Changes are deployed automatically when I push updates</li>\n</ul>\n\n<h3>üé® <strong>Simple Design</strong></h3>\n<ul>\n<li>Clean, academic layout focused on content</li>\n<li>Responsive design that works on mobile</li>\n<li>Uses standard web technologies (HTML, CSS, JavaScript)</li>\n</ul>\n\n<h2>Technical Details</h2>\n\n<p>For those interested in the implementation:</p>\n\n<ul>\n<li><strong>Frontend</strong>: Pure HTML/CSS/JavaScript, no frameworks</li>\n<li><strong>Build Process</strong>: Node.js scripts that process JSON config</li>\n<li><strong>Hosting</strong>: GitHub Pages with custom domain</li>\n<li><strong>Blog System</strong>: Markdown files processed into HTML</li>\n<li><strong>Comments</strong>: Waline comment system for blog posts</li>\n</ul>\n\n<p>The source code is available on GitHub if you want to see how it works or use it for your own site.</p>\n\n<h2>Recent Updates</h2>\n\n<p>I regularly update the site with:</p>\n<ul>\n<li>New publications as they get accepted</li>\n<li>Research news and career updates</li>\n<li>Occasional blog posts about my work</li>\n</ul>\n\n<h2>Contact</h2>\n\n<p>Feel free to reach out if you have questions about my research or want to discuss potential collaborations. You can find my contact information on the main page.</p>\n\n---\n\n<em>This site is a work in progress and gets updated as my research evolves.</em> ",
    "metadata": {
      "title": "Welcome to My Academic Homepage",
      "date": "2025-06-26",
      "description": "A brief introduction to my academic homepage and how it's organized to showcase my research work.",
      "tags": [
        "Homepage",
        "Academic",
        "Research"
      ],
      "image": "teaser/preprint.jpg"
    }
  },
  {
    "id": "how-to-use-this-template",
    "filename": "how-to-use-this-template.md",
    "title": "How to Use This Academic Website Template",
    "date": "2025-06-25",
    "formattedDate": "June 25, 2025",
    "description": "A practical guide to using the config-driven academic website template, covering all features and customization options.",
    "tags": [
      "Tutorial",
      "Website",
      "Academic",
      "Guide"
    ],
    "image": "teaser/preprint.jpg",
    "content": "<h1>How to Use This Academic Website Template</h1>\n\n<p>This is a practical guide for using my config-driven academic website template. I'll walk through all the features and how to customize them for your needs.</p>\n\n<h2>Getting Started</h2>\n\n<h3>1. Fork the Repository</h3>\n<p>Fork <a href=\"https://github.com/Ironieser/ironieser.github.io\">this repository</a> to your GitHub account.</p>\n\n<h3>2. Enable GitHub Pages</h3>\n<ul>\n<li>Go to your repository settings</li>\n<li>Scroll down to \"Pages\" section</li>\n<li>Set source to \"Deploy from a branch\"</li>\n<li>Choose \"master\" branch</li>\n</ul>\n\n<h3>3. Edit the Configuration</h3>\n<p>The main configuration is in <code>config.json</code>. This file controls everything on your website.</p>\n\n<h2>Configuration Structure</h2>\n\n<p>The config file has several main sections:</p>\n\n<p><pre><code class=\"language-json\">{</p>\n<p>  \"personal\": { /<em> Your basic info </em>/ },</p>\n<p>  \"research\": { /<em> Research description and stats </em>/ },</p>\n<p>  \"news\": [ /<em> Recent news items </em>/ ],</p>\n<p>  \"publications\": { /<em> Papers by year </em>/ },</p>\n<p>  \"experience\": [ /<em> Work experience </em>/ ],</p>\n<p>  \"education\": [ /<em> Academic background </em>/ ],</p>\n<p>  \"service\": { /<em> Academic service </em>/ }</p>\n<p>}</code></pre></p>\n\n<h2>Personal Information</h2>\n\n<p>Update the <code>personal</code> section with your details:</p>\n\n<p><pre><code class=\"language-json\">\"personal\": {</p>\n<p>  \"name\": \"Your Name\",</p>\n<p>  \"title\": \"PhD Student in Computer Science\",</p>\n<p>  \"affiliation\": \"Your University\",</p>\n<p>  \"email\": \"your.email@university.edu\",</p>\n<p>  \"profile_image\": \"images/your-photo.jpg\",</p>\n<p>  \"cv_link\": \"files/your-cv.pdf\",</p>\n<p>  \"bio\": [</p>\n<p>    \"First paragraph about yourself...\",</p>\n<p>    \"Second paragraph with research focus...\"</p>\n<p>  ],</p>\n<p>  \"links\": [</p>\n<p>    {</p>\n<p>      \"name\": \"Email\",</p>\n<p>      \"url\": \"mailto:your.email@university.edu\",</p>\n<p>      \"icon\": \"fas fa-envelope\"</p>\n<p>    }</p>\n<p>  ]</p>\n<p>}</code></pre></p>\n\n<h3>Adding Social Links</h3>\n<p>The template supports various social platforms:</p>\n\n<p><pre><code class=\"language-json\">\"links\": [</p>\n<p>  {\"name\": \"Email\", \"url\": \"mailto:...\", \"icon\": \"fas fa-envelope\"},</p>\n<p>  {\"name\": \"Scholar\", \"url\": \"https://scholar.google.com/...\", \"icon\": \"fas fa-graduation-cap\"},</p>\n<p>  {\"name\": \"GitHub\", \"url\": \"https://github.com/...\", \"icon\": \"fab fa-github\"},</p>\n<p>  {\"name\": \"Twitter\", \"url\": \"https://twitter.com/...\", \"icon\": \"fab fa-twitter\"},</p>\n<p>  {\"name\": \"LinkedIn\", \"url\": \"https://linkedin.com/in/...\", \"icon\": \"fab fa-linkedin\"}</p>\n<p>]</code></pre></p>\n\n<h2>Publications Management</h2>\n\n<p>Publications are organized by year in the <code>publications</code> section:</p>\n\n<p><pre><code class=\"language-json\">\"publications\": {</p>\n<p>  \"2025\": [</p>\n<p>    {</p>\n<p>      \"title\": \"Your Paper Title\",</p>\n<p>      \"authors\": [\"Your Name\", \"Collaborator 1\", \"Collaborator 2\"],</p>\n<p>      \"venue\": \"CVPR 2025\",</p>\n<p>      \"venue_type\": \"conference\",</p>\n<p>      \"image\": \"teaser/your-paper.jpg\",</p>\n<p>      \"featured\": true,</p>\n<p>      \"is_oral\": false,</p>\n<p>      \"links\": [</p>\n<p>        {\"name\": \"Paper\", \"url\": \"https://arxiv.org/...\", \"icon\": \"ai ai-arxiv\"},</p>\n<p>        {\"name\": \"Code\", \"url\": \"https://github.com/...\", \"icon\": \"fab fa-github\"}</p>\n<p>      ]</p>\n<p>    }</p>\n<p>  ]</p>\n<p>}</code></pre></p>\n\n<h3>Publication Fields</h3>\n\n<ul>\n<li><code>title</code>: Paper title</li>\n<li><code>authors</code>: List of authors (your name will be highlighted automatically)</li>\n<li><code>venue</code>: Conference/journal name</li>\n<li><code>venue_type</code>: <code>\"conference\"</code>, <code>\"under-review\"</code>, <code>\"preprint\"</code>, or <code>\"working\"</code></li>\n<li><code>image</code>: Path to teaser image</li>\n<li><code>featured</code>: <code>true</code> to show on homepage (optional)</li>\n<li><code>is_oral</code>: <code>true</code> for oral presentations (optional)</li>\n<li><code>links</code>: Array of links (paper, code, dataset, etc.)</li>\n</ul>\n\n<h3>Venue Types</h3>\n\n<p>Different venue types get different styling:</p>\n<ul>\n<li><code>\"conference\"</code>: Blue badge for published papers</li>\n<li><code>\"under-review\"</code>: Gray badge for papers under review</li>\n<li><code>\"preprint\"</code>: Orange badge for preprints</li>\n<li><code>\"working\"</code>: Light blue badge for work in progress</li>\n</ul>\n\n<h3>Link Icons</h3>\n\n<p>Common link icons:</p>\n<ul>\n<li>Paper: <code>\"ai ai-arxiv\"</code> or <code>\"fas fa-file-pdf\"</code></li>\n<li>Code: <code>\"fab fa-github\"</code></li>\n<li>Dataset: <code>\"fas fa-database\"</code></li>\n<li>Video: <code>\"fab fa-youtube\"</code></li>\n<li>Website: <code>\"fas fa-globe\"</code></li>\n</ul>\n\n<h2>News Updates</h2>\n\n<p>Add recent news to the <code>news</code> array:</p>\n\n<p><pre><code class=\"language-json\">\"news\": [</p>\n<p>  {</p>\n<p>    \"date\": \"Dec 2024\",</p>\n<p>    \"content\": \"Paper accepted to <strong>CVPR 2025</strong>!\",</p>\n<p>    \"category\": \"papers\"</p>\n<p>  },</p>\n<p>  {</p>\n<p>    \"date\": \"Aug 2024\",</p>\n<p>    \"content\": \"Started PhD at Your University\",</p>\n<p>    \"category\": \"career\"</p>\n<p>  }</p>\n<p>]</code></pre></p>\n\n<p>Categories include: <code>\"papers\"</code>, <code>\"career\"</code>, <code>\"projects\"</code>, or custom categories.</p>\n\n<h2>Experience and Education</h2>\n\n<h3>Experience Section</h3>\n<p><pre><code class=\"language-json\">\"experience\": [</p>\n<p>  {</p>\n<p>    \"position\": \"Research Intern\",</p>\n<p>    \"company\": \"Company Name\",</p>\n<p>    \"period\": \"Summer 2024\",</p>\n<p>    \"description\": \"Brief description of your work...\",</p>\n<p>    \"logo\": \"images/company-logo.jpg\"</p>\n<p>  }</p>\n<p>]</code></pre></p>\n\n<h3>Education Section</h3>\n<p><pre><code class=\"language-json\">\"education\": [</p>\n<p>  {</p>\n<p>    \"degree\": \"PhD in Computer Science\",</p>\n<p>    \"institution\": \"Your University\",</p>\n<p>    \"period\": \"2024 - Present\",</p>\n<p>    \"details\": \"Focus: Computer Vision and AI\"</p>\n<p>  }</p>\n<p>]</code></pre></p>\n\n<h2>Research Description</h2>\n\n<p>Update the research section with your focus areas:</p>\n\n<p><pre><code class=\"language-json\">\"research\": {</p>\n<p>  \"description\": \"Your research description...\",</p>\n<p>  \"stats\": [</p>\n<p>    \"X+ publications\",</p>\n<p>    \"Y top-tier venues\",</p>\n<p>    \"Z oral presentations\"</p>\n<p>  ]</p>\n<p>}</code></pre></p>\n\n<h2>Images and Files</h2>\n\n<h3>Profile Image</h3>\n<ul>\n<li>Add your photo to <code>images/</code> directory</li>\n<li>Update <code>profile_image</code> path in config</li>\n<li>Recommended: Square image, at least 400x400px</li>\n</ul>\n\n<h3>Publication Teasers</h3>\n<ul>\n<li>Store teaser images in <code>teaser/</code> directory</li>\n<li>Use descriptive names: <code>teaser/your-paper-name.jpg</code></li>\n<li>Recommended: 16:9 aspect ratio, around 800x450px</li>\n</ul>\n\n<h3>CV and Documents</h3>\n<ul>\n<li>Store PDFs in <code>files/</code> directory</li>\n<li>Update <code>cv_link</code> path in config</li>\n</ul>\n\n<h2>Blog Posts</h2>\n\n<p>Create blog posts in the <code>blog/</code> directory:</p>\n\n<ol>\n<li>Create a new <code>.md</code> file</li>\n<li>Add frontmatter metadata</li>\n<li>Write content in Markdown</li>\n</ol>\n\n<p>Example:</p>\n<p><pre><code class=\"language-markdown\">---</p>\n<p>title: \"My Research Experience\"</p>\n<p>date: \"2025-01-01\"</p>\n<p>description: \"Reflections on my PhD journey\"</p>\n<p>tags: [\"Research\", \"PhD\"]</p>\n<p>image: \"teaser/preprint.jpg\"</p>\n---\n\n<h1>My Research Experience</h1>\n\n<p>Your blog content here...</code></pre></p>\n\n<h2>Customization</h2>\n\n<h3>Colors and Styling</h3>\n<ul>\n<li>Main styles are in <code>styles.css</code></li>\n<li>Blog styles in <code>blog.css</code></li>\n<li>Modify CSS variables for color themes</li>\n</ul>\n\n<h3>Adding New Sections</h3>\n<ul>\n<li>Edit the build scripts in <code>.github/scripts/</code></li>\n<li>Add new sections to <code>config.json</code></li>\n<li>Update HTML templates as needed</li>\n</ul>\n\n<h2>Local Development</h2>\n\n<h3>Build Locally</h3>\n<pre><code class=\"language-bash\">python build_local.py</code></pre>\n\n<h3>Preview Locally</h3>\n<pre><code class=\"language-bash\">python local_server.py</code></pre>\n<p>Then visit <code>http://localhost:8000</code></p>\n\n<h2>Deployment</h2>\n\n<p>The site deploys automatically when you push changes to GitHub. The process:</p>\n\n<ol>\n<li>GitHub Actions detects changes to <code>config.json</code> or blog files</li>\n<li>Runs build scripts to generate HTML</li>\n<li>Commits generated files back to repository</li>\n<li>GitHub Pages serves the updated site</li>\n</ol>\n\n<h2>Tips and Best Practices</h2>\n\n<h3>Publication Management</h3>\n<ul>\n<li>Keep publication images consistent in size and style</li>\n<li>Use descriptive filenames for easy organization</li>\n<li>Update featured publications to highlight your best work</li>\n</ul>\n\n<h3>Content Updates</h3>\n<ul>\n<li>Update news regularly to keep the site fresh</li>\n<li>Write blog posts about your research journey</li>\n<li>Keep your CV and contact information current</li>\n</ul>\n\n<h3>Performance</h3>\n<ul>\n<li>Optimize images before uploading</li>\n<li>Keep the config file organized and well-formatted</li>\n<li>Use meaningful commit messages for changes</li>\n</ul>\n\n<h2>Troubleshooting</h2>\n\n<h3>Common Issues</h3>\n\n<strong>Site not updating after changes:</strong>\n<ul>\n<li>Check GitHub Actions tab for build errors</li>\n<li>Ensure <code>config.json</code> has valid JSON syntax</li>\n<li>Wait a few minutes for deployment</li>\n</ul>\n\n<strong>Images not showing:</strong>\n<ul>\n<li>Check file paths in config</li>\n<li>Ensure images are committed to repository</li>\n<li>Use relative paths from website root</li>\n</ul>\n\n<strong>Build errors:</strong>\n<ul>\n<li>Check GitHub Actions logs</li>\n<li>Validate JSON syntax</li>\n<li>Ensure all required fields are present</li>\n</ul>\n\n<h2>Getting Help</h2>\n\n<p>If you run into issues:</p>\n<ul>\n<li>Check the repository's Issues tab</li>\n<li>Look at the build logs in GitHub Actions</li>\n<li>Make sure your config follows the examples</li>\n</ul>\n\n<p>This template is designed to be simple and practical. Start with the basics and gradually add more features as you need them.</p>\n\n---\n\n<em>This guide covers the main features. Feel free to explore the code and customize it further for your specific needs.</em> ",
    "metadata": {
      "title": "How to Use This Academic Website Template",
      "date": "2025-06-25",
      "description": "A practical guide to using the config-driven academic website template, covering all features and customization options.",
      "tags": [
        "Tutorial",
        "Website",
        "Academic",
        "Guide"
      ],
      "image": "teaser/preprint.jpg"
    }
  },
  {
    "id": "mamba-evolution-transformers-ssm",
    "filename": "mamba-evolution-transformers-ssm.md",
    "title": "The Evolution from Mamba to Efficient Recurrent Transformers and SSM (S4)",
    "date": "2024-03-01",
    "formattedDate": "March 01, 2024",
    "description": "This article documents my research work on improving the modeling capabilities of long sequence tasks, primarily covering methods to reduce Transformer complexity to linear complexity, SSM-related work, and explorations in multimodal systems.",
    "tags": [
      "Deep Learning",
      "Transformers",
      "State Space Models"
    ],
    "image": "images/blog/mamba.webp",
    "content": "<h1>The Evolution from Mamba to Efficient Recurrent Transformers and SSM (S4)</h1>\n\n<p>This article documents my survey on improving the modeling capabilities of long sequence tasks, primarily covering methods to reduce Transformer complexity to linear complexity, SSM-related work, and explorations in multimodal systems.</p>\n\n<h2>Article Overview</h2>\n\n<p>In this comprehensive article, I explore:</p>\n\n<ul>\n<li><strong>Linear Complexity Transformers</strong>: Methods to reduce the quadratic complexity of traditional Transformers to linear complexity</li>\n<li><strong>State Space Models (SSM)</strong>: Deep dive into S4 and related architectures</li>\n<li><strong>Mamba Architecture</strong>: Analysis of the latest developments in efficient sequence modeling</li>\n<li><strong>Multimodal Applications</strong>: How these techniques apply to multimodal AI systems</li>\n</ul>\n\n<h2>Key Topics Covered</h2>\n\n<ol>\n<li><strong>Efficient Attention Mechanisms</strong></li>\n<ul>\n</ol>\n<li>Linear attention variants</li>\n<li>Sparse attention patterns</li>\n<li>Low-rank approximations</li>\n</ul>\n\n<ol>\n<li><strong>State Space Models</strong></li>\n<ul>\n</ol>\n<li>Structured State Space (S4) models</li>\n<li>Diagonal State Space (DSS) models</li>\n<li>Connections to RNNs and CNNs</li>\n</ul>\n\n<ol>\n<li><strong>Mamba and Recent Advances</strong></li>\n<ul>\n</ol>\n<li>Selective state spaces</li>\n<li>Hardware-efficient implementations</li>\n<li>Performance comparisons</li>\n</ul>\n\n<ol>\n<li><strong>Practical Applications</strong></li>\n<ul>\n</ol>\n<li>Long sequence modeling</li>\n<li>Multimodal fusion</li>\n<li>Real-world deployment considerations</li>\n</ul>\n\n---\n\n<strong>üìñ Read the full article on Zhihu:</strong> <a href=\"https://zhuanlan.zhihu.com/p/684454735\">The Evolution from Mamba to Efficient Recurrent Transformers and SSM (S4)</a>\n\n<p>This article is written in Chinese and provides detailed technical analysis with code examples and experimental results. </p>",
    "isExternal": true,
    "externalUrl": "https://zhuanlan.zhihu.com/p/684454735",
    "platform": "Zhihu",
    "metadata": {
      "title": "The Evolution from Mamba to Efficient Recurrent Transformers and SSM (S4)",
      "date": "2024-03-01",
      "description": "This article documents my research work on improving the modeling capabilities of long sequence tasks, primarily covering methods to reduce Transformer complexity to linear complexity, SSM-related work, and explorations in multimodal systems.",
      "tags": [
        "Deep Learning",
        "Transformers",
        "State Space Models"
      ],
      "image": "images/blog/mamba.webp",
      "external": true,
      "externalUrl": "https://zhuanlan.zhihu.com/p/684454735",
      "platform": "Zhihu"
    }
  }
];

// Helper function to get blog post by ID
window.getBlogPost = function(id) {
  return window.BLOG_DATA.find(post => post.id === id);
};

// Helper function to get all blog posts
window.getAllBlogPosts = function() {
  return window.BLOG_DATA;
};

console.log('Blog data loaded: ' + window.BLOG_DATA.length + ' posts');
